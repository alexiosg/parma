{\tiny
\ctable[
pos = ht,
cap     = {LP vs NLP Smooth Approximations (fractional)},
caption = {LP vs NLP Smooth Approximations (fractional)},
label   = {table:lpnlp2},
center
]
{lcclcclcclcc}
{
\tnote[]{\tiny {\bf Note:} The Table reports the mean squared error (MSE), mean absolute error (MAE) and maximum error of the weights optimized
under the NLP smooth approximation representation versus the exact LP formulation. The absolute error (AbsErr) in the optimized
risk is also shown. The problem formulation was based on parma.test3 in the parma.tests folder of the \textbf{parma} package, using
the ETF dataset with the fractional objective of minimizing risk/reward.
\LL}
}{
\FL
\begin{tabular*}{1\textwidth}{@{\extracolsep{\fill}}lccccc}
      & \multicolumn{1}{c}{\textbf{MAD}} & \multicolumn{1}{c}{\textbf{MiniMax}} & \multicolumn{1}{c}{\textbf{CVaR}} & \multicolumn{1}{c}{\textbf{EV}} & \multicolumn{1}{c}{\textbf{LPM[1]}} \\
\textbf{MSE[weights]} & 5.35E-10 & 1.28E-35 & 1.34E-23 & 8.89E-19 & 1.25E-24 \\
\textbf{MAE[weights]} & 1.27E-05 & 9.51E-19 & 1.87E-12 & 4.57E-10 & 5.37E-13 \\
\textbf{MaxE[weights]} & 5.93E-05 & 1.39E-17 & 1.02E-11 & 2.71E-09 & 3.20E-12 \\
\textbf{Err[risk]} & 1.05E-07 & 6.94E-18 & 2.62E-12 & 1.91E-08 & 4.66E-15 \\
\end{tabular*}
\LL
}}
